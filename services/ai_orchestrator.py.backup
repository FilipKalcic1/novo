
import asyncio
import json
import logging
import random
import re
from collections import Counter
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple

from openai import AsyncAzureOpenAI, RateLimitError, APIStatusError, APITimeoutError

from config import get_settings
from services.sanitizer import sanitize

logger = logging.getLogger(__name__)
settings = get_settings()

try:
    import tiktoken
except ImportError:
    tiktoken = None


# Token budgeting constants
SINGLE_TOOL_THRESHOLD = 0.98
MAX_TOOLS_FOR_LLM = 10
MAX_HISTORY_MESSAGES = 20
MAX_TOKEN_LIMIT = 8000

# Entity keys to preserve across history truncation
PRESERVED_ENTITY_KEYS = [
    "vehicle_id", "vehicleId", "VehicleId",
    "person_id", "personId", "PersonId",
    "booking_id", "bookingId", "BookingId",
    "plate", "LicencePlate", "registration"
]

# System prompts
DEFAULT_SYSTEM_PROMPT = "Ti si MobilityOne AI asistent. Odgovaraj na hrvatskom. Budi koncizan."
RATE_LIMIT_ERROR_MSG = "Sustav je trenutno preoptereÄ‡en. PokuÅ¡ajte ponovno za minutu."
TIMEOUT_ERROR_MSG = "Sustav nije odgovorio na vrijeme. PokuÅ¡ajte ponovno." 



class AIOrchestrator:
    """
    Orchestrates AI interactions.

    Features:
    - Tool calling with forced execution
    - Parameter extraction
    - Response generation
    - NEW v12.0: Token budgeting & tracking
    - NEW v12.0: Exponential backoff for rate limits
    - NEW v12.0: Smart history management
    """

    # Retry configuration
    MAX_RETRIES = 3
    BASE_DELAY = 1.0
    MAX_JITTER = 0.5

    def __init__(self):
        """Initialize AI orchestrator."""
        # CRITICAL v12.1: Disable SDK's internal retry mechanism
        # SDK default is 60s wait which is too long!
        # We use our own exponential backoff (1-4 seconds)
        self.client = AsyncAzureOpenAI(
            azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,
            api_key=settings.AZURE_OPENAI_API_KEY,
            api_version=settings.AZURE_OPENAI_API_VERSION,
            max_retries=0,  # Disable SDK retry - we handle it ourselves
            timeout=30.0    # 30 second timeout
        )   
        


        self.model = settings.AZURE_OPENAI_DEPLOYMENT_NAME

        # NEW v12.0: Token tracking
        self._total_prompt_tokens = 0
        self._total_completion_tokens = 0
        self._total_requests = 0
        self._rate_limit_hits = 0

        self.tokenizer = None
        if tiktoken:
            try:
                self.tokenizer = tiktoken.get_encoding("cl100k_base")
            except Exception as e:
                logger.warning(f"Tokenizer initialization error: {e}")
                logger.info("Falling back to approximate token counting.")
    
    def _count_tokens(self, messages: List[Dict[str, str]]) -> int:
        """Azure-safe token counting."""
        
        if not self.tokenizer:
            # Fallback (4 slova ~= 1 token)
            return sum(len(m.get("content", "")) for m in messages) // 4

        num_tokens = 0
        for message in messages:
            num_tokens += 3  # Formatiranje poruke (<|start|>, role, itd.)
            for key, value in message.items():
                if value: # Pazi na prazne vrijednosti
                    num_tokens += len(self.tokenizer.encode(str(value)))
                
        num_tokens += 3  # Formatiranje odgovora
        return num_tokens


            
    async def analyze(
        self,
        messages: List[Dict[str, str]],
        tools: Optional[List[Dict]] = None,
        system_prompt: Optional[str] = None,
        forced_tool: Optional[str] = None,
        tool_scores: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:

        # NEW v12.0: Apply Smart History (sliding window)
        filtered_conversation = self._apply_smart_history(messages)

        # Build final message list with system prompt first
        final_messages = []

        if system_prompt:
            final_messages.append({"role": "system", "content": system_prompt})

        final_messages.extend(filtered_conversation)

        # NEW v12.0: Apply Token Budgeting (trim tools if top match is excellent)
        trimmed_tools = self._apply_token_budgeting(tools, tool_scores)

        call_args = {
            "model": self.model,
            "messages": final_messages,
            "temperature": settings.AI_TEMPERATURE,
            "max_tokens": settings.AI_MAX_TOKENS
        }
        # ovdje zavrsava dio sa history i token budgetingom 
        # jer se tu poruke salju kao args u openai azure client


        if trimmed_tools:
            call_args["tools"] = trimmed_tools

            # ACTION-FIRST PROTOCOL: Force specific tool if similarity >= ACTION_THRESHOLD
            if forced_tool:
                call_args["tool_choice"] = {
                    "type": "function",
                    "function": {"name": forced_tool}
                }
                logger.info(f"ğŸ¯ FORCED TOOL CALL: {forced_tool} (similarity >= {settings.ACTION_THRESHOLD})")
            else:
                call_args["tool_choice"] = "auto"

        # NEW v12.0: Retry with exponential backoff
        last_error = None

        for attempt in range(self.MAX_RETRIES):
            try:
                response = await self.client.chat.completions.create(**call_args)
                self._total_requests += 1

                # NEW v12.0: Track token usage
                if hasattr(response, 'usage') and response.usage:
                    prompt_tokens = response.usage.prompt_tokens
                    completion_tokens = response.usage.completion_tokens

                    self._total_prompt_tokens += prompt_tokens
                    self._total_completion_tokens += completion_tokens

                    logger.info(
                        f"ğŸ« Tokens: prompt={prompt_tokens}, "
                        f"completion={completion_tokens}, "
                        f"total_session={self._total_prompt_tokens + self._total_completion_tokens}"
                    )

                if not response.choices:
                    logger.error("Empty AI response")
                    return {"type": "error", "content": "AI returned empty response"}

                message = response.choices[0].message

                # Tool call
                if message.tool_calls and len(message.tool_calls) > 0:
                    tool_call = message.tool_calls[0]

                    try:
                        arguments = json.loads(tool_call.function.arguments)
                    except json.JSONDecodeError:
                        logger.warning(f"Invalid tool arguments: {tool_call.function.arguments[:100]}")
                        arguments = {}

                    logger.info(f"AI tool call: {tool_call.function.name}")

                    return {
                        "type": "tool_call",
                        "tool": tool_call.function.name,
                        "parameters": arguments,
                        "tool_call_id": tool_call.id,
                        "raw_message": message
                    }

                # Text response
                content = message.content or ""
                logger.info(f"AI text response: {len(content)} chars")

                return {"type": "text", "content": content}

            except RateLimitError as e:
                self._rate_limit_hits += 1
                last_error = e

                if attempt < self.MAX_RETRIES - 1:
                    delay = self._calculate_backoff(attempt)
                    logger.warning(
                        f" Rate limit hit (RateLimitError). "
                        f"Retry {attempt + 1}/{self.MAX_RETRIES} after {delay:.2f}s. "
                        f"Total rate limits: {self._rate_limit_hits}"
                    )
                    await asyncio.sleep(delay)
                    continue
                else:
                    logger.error(
                        f" Rate limit exceeded after {self.MAX_RETRIES} retries"
                    )
                    return {
                        "type": "error",
                        "content": "Sustav je trenutno preoptereÄ‡en. PokuÅ¡ajte ponovno za minutu."
                    }

            except APIStatusError as e:
                # Azure OpenAI returns APIStatusError for 429
                if e.status_code == 429:
                    self._rate_limit_hits += 1
                    last_error = e

                    if attempt < self.MAX_RETRIES - 1:
                        delay = self._calculate_backoff(attempt)
                        logger.warning(
                            f" Rate limit hit (APIStatusError 429). "
                            f"Retry {attempt + 1}/{self.MAX_RETRIES} after {delay:.2f}s. "
                            f"Total rate limits: {self._rate_limit_hits}"
                        )
                        await asyncio.sleep(delay)
                        continue
                    else:
                        logger.error(
                            f" Rate limit exceeded after {self.MAX_RETRIES} retries"
                        )
                        return {
                            "type": "error",
                            "content": "Sustav je trenutno preoptereÄ‡en. PokuÅ¡ajte ponovno za minutu."
                        }
                else:
                    # Other API errors (400, 401, 500, etc.) - don't retry
                    logger.error(f"API error {e.status_code}: {e.message}")
                    return {"type": "error", "content": f"API greÅ¡ka: {e.message}"}

            except APITimeoutError as e:
                last_error = e
                if attempt < self.MAX_RETRIES - 1:
                    delay = self._calculate_backoff(attempt)
                    logger.warning(
                        f" API timeout. "
                        f"Retry {attempt + 1}/{self.MAX_RETRIES} after {delay:.2f}s"
                    )
                    await asyncio.sleep(delay)
                    continue
                else:
                    logger.error(f" API timeout after {self.MAX_RETRIES} retries")
                    return {
                        "type": "error",
                        "content": "Sustav nije odgovorio na vrijeme. PokuÅ¡ajte ponovno."
                    }

            except Exception as e:
                logger.error(f"AI error: {e}", exc_info=True)
                return {"type": "error", "content": f"GreÅ¡ka: {e}"}

        # Should not reach here, but just in case
        return {"type": "error", "content": f"GreÅ¡ka: {last_error}"}

    def _calculate_backoff(self, attempt: int) -> float:
        """Calculate exponential backoff with jitter."""
        exponential_delay = (2 ** attempt) * self.BASE_DELAY
        jitter = random.uniform(0, self.MAX_JITTER)
        return exponential_delay + jitter

    def _apply_token_budgeting(
        self,
        tools: Optional[List[Dict]],
        tool_scores: Optional[List[Dict]]
    ) -> Optional[List[Dict]]:
        """
        Apply token budgeting - trim tools if top match is excellent.

        NEW v12.0: If best tool score >= SINGLE_TOOL_THRESHOLD (0.98),
        send only that tool to LLM. This saves ~80% of token cost for tool descriptions.

        CRITICAL REQUIREMENTS:
        1. tools and tool_scores MUST be in the SAME ORDER (sorted by score DESC)
        2. tool_scores MUST contain 'name' and 'score' fields
        3. tools MUST be OpenAI tool schemas with structure: {"type": "function", "function": {"name": "..."}}

        Args:
            tools: List of tool schemas (sorted by score DESC)
            tool_scores: List of {name, score, ...} dicts (sorted by score DESC)

        Returns:
            Trimmed list of tools (maintains sort order)
        """
        if not tools:
            return tools

        if not tool_scores:
            # No scores, apply simple limit
            if len(tools) > MAX_TOOLS_FOR_LLM:
                logger.info(
                    f" Token budget: Trimming {len(tools)} â†’ {MAX_TOOLS_FOR_LLM} tools"
                )
                return tools[:MAX_TOOLS_FOR_LLM]
            return tools

        # VALIDATION: Ensure tools and tool_scores are aligned
        if len(tools) != len(tool_scores):
            logger.warning(
                f" Token budgeting: tools count ({len(tools)}) != "
                f"tool_scores count ({len(tool_scores)}). This may cause incorrect tool selection!"
            )

        # Find best score (tool_scores should already be sorted DESC by message_engine)
        best = tool_scores[0] if tool_scores else None

        if best and best.get("score", 0) >= SINGLE_TOOL_THRESHOLD:
            # Excellent match - send only this tool
            best_name = best.get("name")

            # Find matching tool by name
            single_tool = next(
                (t for t in tools if t.get("function", {}).get("name") == best_name),
                None
            )

            if single_tool:
                logger.info(
                    f" Token budget: SINGLE TOOL MODE - "
                    f"{best_name} (score={best.get('score'):.3f} >= {SINGLE_TOOL_THRESHOLD})"
                )
                return [single_tool]
            else:
                logger.error(
                    f" Token budgeting: Best tool '{best_name}' not found in tools list! "
                    f"Available tools: {[t.get('function', {}).get('name') for t in tools]}"
                )

        # Apply limit (tools already sorted by score DESC)
        if len(tools) > MAX_TOOLS_FOR_LLM:
            logger.info(
                f"Token budget: Trimming {len(tools)} â†’ {MAX_TOOLS_FOR_LLM} tools "
                f"(keeping top {MAX_TOOLS_FOR_LLM} by score)"
            )
            return tools[:MAX_TOOLS_FOR_LLM]

        return tools

    
    def _apply_smart_history(
        self,
        messages: List[Dict[str, str]]
    ) -> List[Dict[str, str]]:

        # 1. IZDVAJANJE SYSTEM PROMPTA

        system_message = None
        if messages and messages[0]["role"] == "system":
            system_message = messages[0]
            conversation = messages[1:] # Ostatak razgovora
        else:
            conversation = messages

        # 2. PROVJERA TOKENA (Preciznije od broja poruka)

        current_tokens = self._count_tokens(messages)
        
        # Ako smo ispod limita, ne diraj niÅ¡ta
        if current_tokens <= MAX_TOKEN_LIMIT:
            return messages

        # 3. REZANJE KONTEKSTA


        split_index = len(conversation) - MAX_HISTORY_MESSAGES
        if split_index < 0: split_index = 0
        
        to_summarize = conversation[:split_index]
        recent_history = conversation[split_index:]

        # 4. SAÅ½IMANJE (Bolje od samih entiteta)
        if to_summarize:

            summary_text = self._summarize_conversation(to_summarize)
            
            # Ubacujemo saÅ¾etak KAO SYSTEM poruku, ali ODMAH NAKON glavnog system prompta
            context_message = {
                "role": "system", 
                "content": f"SaÅ¾etak prethodnog razgovora: {summary_text}"
            }
            
            # 5. REKONSTRUKCIJA
            final_messages = []
            if system_message:
                final_messages.append(system_message)
            
            final_messages.append(context_message)
            final_messages.extend(recent_history)
            
            return final_messages

        return messages

    def _extract_entities(
        self,
        messages: List[Dict[str, str]]
    ) -> Dict[str, str]:
        """Extract entity references from messages."""
        entities = {}

        for msg in messages:
            content = msg.get("content", "")
            if not content:
                continue

            # Look for UUID patterns (entity IDs)
            import re
            uuid_pattern = r'([a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12})'
            uuids = re.findall(uuid_pattern, content.lower())

            for uuid in uuids:
                # Try to identify what type of entity
                content_lower = content.lower()
                if "vehicle" in content_lower or "vozil" in content_lower:
                    entities["VehicleId"] = uuid
                elif "person" in content_lower or "osob" in content_lower:
                    entities["PersonId"] = uuid
                elif "booking" in content_lower or "rezerv" in content_lower:
                    entities["BookingId"] = uuid
                    
            # Look for license plates
            plate_pattern = r'([A-ZÄŒÄ†Å½Å Ä]{2}[\s\-]?\d{3,4}[\s\-]?[A-ZÄŒÄ†Å½Å Ä]{1,2})'
            plates = re.findall(plate_pattern, content.upper())
            if plates:
                entities["LicencePlate"] = plates[-1]  # Most recent

        return entities

    def _format_entity_context(self, entities: Dict[str, str]) -> str:
        """Format extracted entities as context string."""
        parts = []
        for key, value in entities.items():
            parts.append(f"{key}={value}")
        return ", ".join(parts)

    def _summarize_conversation(self, messages: List[Dict[str, str]]) -> str:
        """
        Summarize old conversation messages into a concise context.

        Args:
            messages: List of messages to summarize

        Returns:
            Summary text
        """
        # Extract key entities from messages
        entities = self._extract_entities(messages)

        # Build summary from entities
        summary_parts = []

        if entities:
            entity_context = self._format_entity_context(entities)
            summary_parts.append(f"Ranije entiteti: {entity_context}")

        # Count message types
        user_messages = [m for m in messages if m.get("role") == "user"]
        assistant_messages = [m for m in messages if m.get("role") == "assistant"]
        tool_messages = [m for m in messages if m.get("role") == "tool"]

        summary_parts.append(
            f"Prethodnih {len(messages)} poruka "
            f"({len(user_messages)} user, {len(assistant_messages)} assistant, {len(tool_messages)} tool calls)"
        )

        return ". ".join(summary_parts)

    def get_token_stats(self) -> Dict[str, Any]:
        """Get token usage statistics."""
        return {
            "total_prompt_tokens": self._total_prompt_tokens,
            "total_completion_tokens": self._total_completion_tokens,
            "total_tokens": self._total_prompt_tokens + self._total_completion_tokens,
            "total_requests": self._total_requests,
            "rate_limit_hits": self._rate_limit_hits,
            "avg_tokens_per_request": (
                (self._total_prompt_tokens + self._total_completion_tokens) / self._total_requests
                if self._total_requests > 0 else 0
            )
        }
    
    async def generate_response(
        self,
        prompt: str,
        context: Optional[str] = None
    ) -> str:
        """
        Generate natural language response.
        
        Args:
            prompt: User prompt
            context: Additional context
            
        Returns:
            Generated text
        """
        messages = []
        
        system = "Ti si MobilityOne AI asistent. Odgovaraj na hrvatskom. Budi koncizan."
        messages.append({"role": "system", "content": system})
        
        if context:
            messages.append({"role": "system", "content": f"Kontekst: {context}"})
        
        messages.append({"role": "user", "content": prompt})
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.3,
                max_tokens=500
            )
            
            return response.choices[0].message.content or ""
            
        except Exception as e:
            logger.error(f"Generate response error: {e}")
            return "DoÅ¡lo je do greÅ¡ke. PokuÅ¡ajte ponovno."
    
    async def extract_parameters(
        self,
        user_input: str,
        required_params: List[Dict[str, str]],
        context: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Extract parameters from user input.
        
        Args:
            user_input: User message
            required_params: [{name, type, description}]
            context: Additional context
            
        Returns:
            Extracted parameters
        """
        param_desc = "\n".join([
            f"- {p['name']} ({p['type']}): {p.get('description', '')}"
            for p in required_params
        ])
        
        today = datetime.now()
        tomorrow = today + timedelta(days=1)
        
        system = f"""Izvuci parametre iz korisnikove poruke.
Vrati JSON objekt s vrijednostima. Koristi null za nedostajuÄ‡e parametre.

Parametri:
{param_desc}

Datumski kontekst:
- Danas: {today.strftime('%Y-%m-%d')} ({today.strftime('%A')})
- Sutra: {tomorrow.strftime('%Y-%m-%d')}

Format vremena: ISO 8601 (YYYY-MM-DDTHH:MM:SS)

Hrvatske rijeÄi:
- "sutra" = tomorrow
- "danas" = today
- "od X do Y" = from X to Y
- "ujutro" = 08:00
- "popodne" = 14:00
- "cijeli dan" = 08:00 do 18:00

Vrati SAMO JSON, bez drugog teksta."""
        
        if context:
            system += f"\n\nDodatni kontekst: {context}"
        
        try:
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.1,
                max_tokens=300
            )
            
            content = response.choices[0].message.content or "{}"
            
            # Clean markdown
            content = content.strip()
            if content.startswith("```"):
                content = content.split("```")[1]
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            return json.loads(content)
            
        except json.JSONDecodeError:
            logger.warning("Parameter extraction JSON error")
            return {}
        except Exception as e:
            logger.error(f"Parameter extraction error: {e}")
            return {}
    
    def build_system_prompt(
        self,
        user_context: Dict[str, Any],
        flow_context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Build system prompt with context.
        
        Args:
            user_context: User info
            flow_context: Current flow state
            
        Returns:
            System prompt
        """
        name = user_context.get("display_name", "Korisnik")
        person_id = user_context.get("person_id", "")
        vehicle = user_context.get("vehicle", {})
        
        today = datetime.now()
        
        prompt = f"""Ti si MobilityOne AI asistent za upravljanje voznim parkom.
Komuniciraj na HRVATSKOM jeziku. Budi KONCIZAN i JASAN.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KORISNIK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- Ime: {name}
- ID: {person_id[:12]}...
- Datum: {today.strftime('%d.%m.%Y')} ({today.strftime('%A')})
"""
        
        if vehicle and vehicle.get("plate"):
            prompt += f"""- Vozilo: {vehicle.get('name', 'N/A')} ({vehicle.get('plate', 'N/A')})
- KilometraÅ¾a: {vehicle.get('mileage', 'N/A')} km
"""
        
        prompt += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MOGUÄ†NOSTI I ODABIR ALATA
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ImaÅ¡ pristup API funkcijama. Sustav koristi semantiÄku
pretragu i SORTIRA alate po relevantnosti.

KRITIÄŒNO - ODABIR ALATA:
- Alati su sortirani po RELEVANTNOSTI za korisnikov upit
- PRVI alat u listi je NAJBOLJI match - koristi ga!
- Ako nisi siguran, UVIJEK odaberi PRVI alat
- NE koristi POST/PUT/DELETE ako korisnik pita za podatke (koristi GET)
- "moje vozilo" â†’ koristi get_MasterData, NE get_Vehicles
- "koja je kilometraÅ¾a" â†’ koristi alat koji vraÄ‡a podatke, NE calendar

TVOJ POSAO:
1. RAZUMJETI Å¡to korisnik Å¾eli
2. ODABRATI PRVI alat ako odgovara upitu
3. IZVUÄ†I parametre iz poruke
4. POZVATI alat s ispravnim parametrima

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PRAVILA ZA DATUME
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- "sutra" = sutraÅ¡nji datum
- "danas" = danaÅ¡nji datum
- ISO 8601 format: YYYY-MM-DDTHH:MM:SS
- "od 9 do 17" = FromTime: ...T09:00:00, ToTime: ...T17:00:00

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
KRITIÄŒNO: ZABRANJENO IZMIÅ LJANJE PODATAKA!
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
NIKADA ne izmiÅ¡ljaj NIÅ TA - SVE mora doÄ‡i iz API-ja! 

ZABRANJENO izmiÅ¡ljati:
- Nazive tvrtki (leasing kuÄ‡e, dobavljaÄi, itd.)
- Email adrese
- Telefonske brojeve
- Adrese
- Bilo kakve kontakt podatke
- UUID-ove ili ID-eve
- Imena osoba
- Registracijske oznake
- Bilo kakve poslovne podatke
- bilo Å¡ta drugo ...

podaci su doslovni.

AKO NEMAÅ  PODATAK IZ API ODGOVORA:
â†’ RECI: "Nemam tu informaciju u sustavu."
â†’ NE izmiÅ¡ljaj nazive tvrtki kao "LeasingCo", "HighwaysInc", itd.!
â†’ NE koristi generiÄke placeholder nazive!
â†’ PITAJ korisnika ili pozovi odgovarajuÄ‡i API alat!

PRIMJER ISPRAVNOG PONAÅ ANJA:
- Korisnik pita: "Koja je moja leasing kuÄ‡a?"
- Ti MORAÅ  pozvati API alat za dohvat podataka
- Ako API ne vrati polje "LeasingProvider" â†’ reci "Nemam tu informaciju"
- NIKADA ne izmiÅ¡ljaj naziv leasing kuÄ‡e!

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
REZERVACIJA VOZILA (BOOKING FLOW)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Kada korisnik traÅ¾i vozilo ili Å¾eli rezervirati:

POTREBNI PARAMETRI:
1. FromTime - datum i vrijeme polaska (obavezno)
2. ToTime - datum i vrijeme povratka (obavezno)
3. OdrediÅ¡te - gdje putuje (opciono za sada)
4. Svrha puta - zaÅ¡to putuje (opciono za sada)
5. Broj putnika - koliko osoba (opciono za sada)

FLOW:
1. Ako korisnik nije naveo FromTime/ToTime â†’ PITAJ GA
   Primjer: "Za kada vam treba vozilo? (npr. sutra od 8:00 do 17:00)"

2. Kada imaÅ¡ FromTime i ToTime â†’ pozovi get_AvailableVehicles
   Parametri: from=YYYY-MM-DDTHH:MM:SS, to=YYYY-MM-DDTHH:MM:SS

3. Ako nema slobodnih vozila â†’ javi korisniku i predloÅ¾i drugi termin

4. Ako ima slobodnih â†’ prikaÅ¾i PRVO slobodno vozilo i pitaj:
   "PronaÅ¡ao sam slobodno vozilo: [naziv] ([registracija]).
    Å½elite li potvrditi rezervaciju?"

5. Ako korisnik potvrdi â†’ pozovi post_VehicleCalendar s:
   - AssignedToId: korisnikov PersonId (iz konteksta)
   - VehicleId: ID odabranog vozila
   - FromTime: vrijeme polaska
   - ToTime: vrijeme povratka
   - AssigneeType: 1
   - EntryType: 0

6. Potvrdi uspjeÅ¡nu rezervaciju ili javi greÅ¡ku

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STIL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- KRATKI odgovori na hrvatskom
- SVE informacije MORAJU doÄ‡i iz API odgovora!
- NE izmiÅ¡ljaj podatke - koristi alate!
- Ako nedostaju parametri, PITAJ korisnika
- Ako API ne vrati podatak, reci "Nemam tu informaciju"
"""
        
        if flow_context and flow_context.get("current_flow"):
            prompt += f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TRENUTNI TOK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- Flow: {flow_context.get('current_flow')}
- Stanje: {flow_context.get('state')}
- Parametri: {flow_context.get('parameters', {})}
- Nedostaju: {flow_context.get('missing_params', [])}
"""
        
        return prompt
